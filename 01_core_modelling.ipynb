{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70303e62-f330-47cd-8ed0-ef68166e98fa",
   "metadata": {},
   "source": [
    "# Notebook 01: Core Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3b796-acb0-4b06-a5ad-994d7852f44b",
   "metadata": {},
   "source": [
    "## Cell 1 — Purpose + Research Question + Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588677ea-ca80-4a98-96f6-76e759bfa0da",
   "metadata": {},
   "source": [
    "## Business Research Question (RQ)\n",
    "How can predictive modelling of lead characteristics and agent performance variation be used to design an evidence-based system for optimising agent–lead allocation across HD’s campaigns?\n",
    "\n",
    "## Research Objective \n",
    "To develop a lead-level conversion model incorporating lead, campaign, and agent information, and to assess how model outputs could inform agent–lead allocation decisions across HD’s campaigns.\n",
    "\n",
    "This objective is addressed in two analytical stages:\n",
    "1. **Conversion modelling:** Build and evaluate a predictive model to estimate the probability that a lead converts into a sale.\n",
    "2. **Allocation implications:** Interpret model outputs to examine agent performance variation and discuss how predicted probabilities could support lead allocation decisions.\n",
    "\n",
    "## Unit of analysis\n",
    "- **Lead-level** (one row per lead).\n",
    "- Outcome variable: **sale_flag** (1 = lead matched to a sale record, 0 = otherwise).\n",
    "\n",
    "## Datasets used\n",
    "- **Primary (core modelling):** *HD Leads and Sales last 12 months* (Leads, Sales, Agents, List IDs tabs).\n",
    "- **Optional (diagnostics only):** *sales_unmatched_after_join* (used only to quantify unmatched sales as a limitation).\n",
    "- **Excluded:** *Health_Deal_Lead_Report_created* (not required for the scoped objective)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421fe8c6-4f34-4207-b93e-6da785a51dbf",
   "metadata": {},
   "source": [
    "## Cell 2 — Imports + config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c64da661-d706-4102-a2a6-28c4aaaf8a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell sets up all libraries and global settings used throughout the notebook\n",
    "\n",
    "import io                     # Used to handle in-memory byte streams (for decrypted Excel file)\n",
    "import numpy as np            # Numerical operations and arrays\n",
    "import pandas as pd           # Data manipulation and DataFrames\n",
    "import msoffcrypto            # Decrypts password-protected Excel files\n",
    "\n",
    "# ---- File configuration ----\n",
    "# Path to the password-protected Excel file\n",
    "FILE_PATH = \"HD Leads and Sales last 12 months.xlsx\"\n",
    "\n",
    "# Password required to open the Excel file\n",
    "PASSWORD = \"K33pS@fePlease123\"\n",
    "\n",
    "# ---- Pandas display settings (for readability only) ----\n",
    "pd.set_option(\"display.max_columns\", 200)   # Show all columns when printing DataFrames\n",
    "pd.set_option(\"display.width\", 140)         # Prevent line wrapping in DataFrame output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7a2b6-aa5c-4b8a-8dd5-2ff9fc0f7901",
   "metadata": {},
   "source": [
    "## Cell 3 — Decrypt the password-protected workbook and load the sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020c39c7-f753-4e81-9ac7-24dbf22c7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell reads the Excel file securely in-memory (no decrypted file written to disk),\n",
    "# then loads the four sheets into pandas DataFrames.\n",
    "\n",
    "# Open the encrypted Excel file in binary mode (required for decryption)\n",
    "with open(FILE_PATH, \"rb\") as f:\n",
    "    office_file = msoffcrypto.OfficeFile(f)          # Create an OfficeFile object from the encrypted workbook\n",
    "    office_file.load_key(password=PASSWORD)          # Provide the password so the file can be decrypted\n",
    "    decrypted = io.BytesIO()                         # Create an in-memory buffer for the decrypted content\n",
    "    office_file.decrypt(decrypted)                   # Decrypt the workbook into the in-memory buffer\n",
    "\n",
    "# Reset the buffer pointer to the beginning so pandas can read it\n",
    "decrypted.seek(0)\n",
    "\n",
    "# Create an ExcelFile object so we can read multiple sheets efficiently\n",
    "xls = pd.ExcelFile(decrypted, engine=\"openpyxl\")\n",
    "\n",
    "# Load each sheet by its exact name into a DataFrame\n",
    "leads_raw  = pd.read_excel(xls, sheet_name=\"Leads\")     # All lead records (base population)\n",
    "sales_raw  = pd.read_excel(xls, sheet_name=\"Sales\")     # Sales outcomes (subset of leads that converted)\n",
    "agents_raw = pd.read_excel(xls, sheet_name=\"Agents\")    # Agent reference table (names + VICIDIAL_ID)\n",
    "lists_raw  = pd.read_excel(xls, sheet_name=\"List IDs\")  # Campaign/list reference table (IDs + names)\n",
    "\n",
    "# Print quick checks to confirm everything loaded correctly\n",
    "print(\"Sheets detected:\", xls.sheet_names)              # Confirms sheet names in the workbook\n",
    "print(\"Shapes (raw):\",                                 # Confirms row/column counts for each sheet\n",
    "      leads_raw.shape, sales_raw.shape, agents_raw.shape, lists_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a48dc-3eb5-44de-91dd-f783509a5679",
   "metadata": {},
   "source": [
    "## Cell 4 - Standardise column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f135cd-a86a-43d0-b991-e7980e001c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This converts column names into consistent snake_case so we can reference them reliably in code.\n",
    "\n",
    "def clean_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardise columns to snake_case:\n",
    "    - strip leading/trailing spaces\n",
    "    - replace internal whitespace with underscores\n",
    "    - remove non-alphanumeric characters (except underscores)\n",
    "    - convert to lowercase\n",
    "    \"\"\"\n",
    "    out = df.copy()  # Work on a copy so the original raw DataFrame remains available if needed\n",
    "    out.columns = (\n",
    "        out.columns.astype(str)                         # Ensure all column labels are strings\n",
    "        .str.strip()                                    # Remove leading/trailing whitespace\n",
    "        .str.replace(r\"\\s+\", \"_\", regex=True)           # Replace one/more spaces with underscore\n",
    "        .str.replace(r\"[^0-9a-zA-Z_]+\", \"\", regex=True) # Remove special characters\n",
    "        .str.lower()                                    # Convert to lowercase\n",
    "    )\n",
    "    return out\n",
    "\n",
    "# Create cleaned versions of each sheet (recommended for all downstream analysis)\n",
    "leads  = clean_cols(leads_raw)    # Leads table (base population)\n",
    "sales  = clean_cols(sales_raw)    # Sales table (conversion outcomes)\n",
    "agents = clean_cols(agents_raw)   # Agent reference table\n",
    "lists  = clean_cols(lists_raw)    # Campaign/list reference table\n",
    "\n",
    "# Quick check: print key column names to confirm standardisation worked\n",
    "print(\"Leads columns (cleaned):\", list(leads.columns))\n",
    "print(\"Sales columns (cleaned):\", list(sales.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45001ec4-8cc7-4cd8-9b50-d06c443d018a",
   "metadata": {},
   "source": [
    "## Cell 5 — Data Validation & Consistency Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbaa8b7-5f62-47d4-90f9-58bb5b36ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This ensures date fields are usable for time-based matching and analysis.\n",
    "\n",
    "# Convert Leads date/time columns to datetime (invalid parsing becomes NaT)\n",
    "leads[\"entry_date\"] = pd.to_datetime(leads[\"entry_date\"], errors=\"coerce\")                 # Lead creation timestamp\n",
    "leads[\"last_local_call_time\"] = pd.to_datetime(leads[\"last_local_call_time\"], errors=\"coerce\")  # Last call timestamp\n",
    "\n",
    "# Convert Sales date/time columns to datetime (invalid parsing becomes NaT)\n",
    "sales[\"sale_date\"] = pd.to_datetime(sales[\"sale_date\"], errors=\"coerce\")                  # Sale date\n",
    "sales[\"payment_date\"] = pd.to_datetime(sales[\"payment_date\"], errors=\"coerce\")            # Payment date (if present)\n",
    "sales[\"sale_date__time\"] = pd.to_datetime(sales[\"sale_date__time\"], errors=\"coerce\")      # Sale timestamp (if present)\n",
    "\n",
    "# Print date ranges to confirm dataset coverage and overlap\n",
    "print(\"Leads entry_date range:\", leads[\"entry_date\"].min(), \"→\", leads[\"entry_date\"].max())\n",
    "print(\"Sales sale_date range:\", sales[\"sale_date\"].min(), \"→\", sales[\"sale_date\"].max())\n",
    "\n",
    "# Check missingness in key identifiers required for matching and modelling\n",
    "key_cols_leads = [\"lead_id\", \"entry_date\", \"phone_number\", \"email\", \"list_id\", \"lead_source\", \"user\"]\n",
    "key_cols_sales = [\"sale_date\", \"contact_mobile_ph\", \"contact_home_ph\", \"email_id\", \"phone_agent\"]\n",
    "\n",
    "print(\"\\nMissingness (Leads):\")\n",
    "print(leads[key_cols_leads].isna().mean().sort_values(ascending=False).map(lambda x: f\"{x:.2%}\"))\n",
    "\n",
    "print(\"\\nMissingness (Sales):\")\n",
    "print(sales[key_cols_sales].isna().mean().sort_values(ascending=False).map(lambda x: f\"{x:.2%}\"))\n",
    "\n",
    "# Confirm basic row counts (should match your raw shapes)\n",
    "print(\"\\nRow counts:\")\n",
    "print(\"Leads:\", len(leads), \"| Sales:\", len(sales))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa9500-b89c-43fe-b55f-37fc22fee92b",
   "metadata": {},
   "source": [
    "## Cell 6 — Create matching keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac428fc-f24d-471b-92f7-6b9cfb9dff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Standardise phone numbers and emails so Sales records can be matched to Leads reliably.\n",
    "# - Australian phone numbers only (no country-code stripping required).\n",
    "\n",
    "def normalise_phone(x):\n",
    "    \"\"\"\n",
    "    Convert a phone value to a comparable key:\n",
    "    - keep digits only\n",
    "    - remove leading zeros (formatting differences across systems)\n",
    "    Returns NaN if the input is missing or empty after cleaning.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):                                   # Missing value remains missing\n",
    "        return np.nan\n",
    "    s = \"\".join(ch for ch in str(x) if ch.isdigit()) # Keep digits only\n",
    "    if s == \"\":                                      # Empty after cleaning\n",
    "        return np.nan\n",
    "\n",
    "    # Remove leading zeros caused by formatting/export differences\n",
    "    while len(s) > 0 and s[0] == \"0\":\n",
    "        s = s[1:]\n",
    "\n",
    "    return s if s != \"\" else np.nan\n",
    "\n",
    "def normalise_email(x):\n",
    "    \"\"\"\n",
    "    Convert an email value to a comparable key:\n",
    "    - lower-case\n",
    "    - strip surrounding whitespace\n",
    "    Returns NaN if missing or blank.\n",
    "    \"\"\"\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    s = str(x).strip().lower()\n",
    "    return s if s != \"\" else np.nan\n",
    "\n",
    "# --- Leads keys ---\n",
    "# Primary identifier for matching\n",
    "leads[\"phone_key\"] = leads[\"phone_number\"].map(normalise_phone)\n",
    "\n",
    "# Secondary identifier for matching\n",
    "leads[\"email_key\"] = leads[\"email\"].map(normalise_email)\n",
    "\n",
    "# --- Sales keys ---\n",
    "# Mobile phone is preferred; home phone is used as a fallback\n",
    "sales[\"phone_key_mobile\"] = sales[\"contact_mobile_ph\"].map(normalise_phone)\n",
    "sales[\"phone_key_home\"]   = sales[\"contact_home_ph\"].map(normalise_phone)\n",
    "sales[\"phone_key\"]        = sales[\"phone_key_mobile\"].fillna(sales[\"phone_key_home\"])\n",
    "\n",
    "# Email identifier\n",
    "sales[\"email_key\"] = sales[\"email_id\"].map(normalise_email)\n",
    "\n",
    "# --- Key quality checks (used later for diagnostics and limitations) ---\n",
    "print(\"Null rates (matching keys):\")\n",
    "print(\"  Leads.phone_key:\", f\"{leads['phone_key'].isna().mean():.2%}\")\n",
    "print(\"  Sales.phone_key:\", f\"{sales['phone_key'].isna().mean():.2%}\")\n",
    "print(\"  Leads.email_key:\", f\"{leads['email_key'].isna().mean():.2%}\")\n",
    "print(\"  Sales.email_key:\", f\"{sales['email_key'].isna().mean():.2%}\")\n",
    "\n",
    "# Check whether Sales identifiers generally exist in Leads\n",
    "lead_phone_set  = set(leads[\"phone_key\"].dropna().unique())\n",
    "sales_phone_set = set(sales[\"phone_key\"].dropna().unique())\n",
    "lead_email_set  = set(leads[\"email_key\"].dropna().unique())\n",
    "sales_email_set = set(sales[\"email_key\"].dropna().unique())\n",
    "\n",
    "print(\"\\nKey overlap (unique values):\")\n",
    "print(f\"  Sales phones present in Leads: {len(sales_phone_set & lead_phone_set)}/{len(sales_phone_set)} \"\n",
    "      f\"({len(sales_phone_set & lead_phone_set)/max(1,len(sales_phone_set)):.1%})\")\n",
    "print(f\"  Sales emails present in Leads: {len(sales_email_set & lead_email_set)}/{len(sales_email_set)} \"\n",
    "      f\"({len(sales_email_set & lead_email_set)/max(1,len(sales_email_set)):.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d47b3bd-c070-401c-9832-e05c20e3add0",
   "metadata": {},
   "source": [
    "## Cell 7 — Deterministic Sales → Lead matching (one row per sale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1e183-2e39-4e64-aa2e-5a70d737e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Match each sale to at most ONE lead.\n",
    "# - Enforce logical timing (lead created before sale).\n",
    "# - Use a clear, reproducible rule \n",
    "\n",
    "# Create a stable unique identifier for each sale row\n",
    "sales = sales.copy()\n",
    "sales[\"_sale_row_id\"] = np.arange(len(sales))   # One ID per original sales row\n",
    "\n",
    "# Keep only the columns needed for matching and timing\n",
    "sales_match_cols = [\n",
    "    \"_sale_row_id\", \"sale_date\", \"phone_key\", \"email_key\", \"phone_agent\"\n",
    "]\n",
    "leads_match_cols = [\n",
    "    \"lead_id\", \"entry_date\", \"phone_key\", \"email_key\", \"user\", \"list_id\"\n",
    "]\n",
    "\n",
    "sales_m = sales[sales_match_cols].copy()\n",
    "leads_m = leads[leads_match_cols].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 1: PHONE-based matching\n",
    "# -----------------------------\n",
    "# Join sales to leads on phone_key (many-to-many possible at this stage)\n",
    "phone_join = sales_m.merge(\n",
    "    leads_m,\n",
    "    how=\"left\",\n",
    "    on=\"phone_key\",\n",
    "    suffixes=(\"_sale\", \"_lead\")\n",
    ")\n",
    "\n",
    "# Keep only logically valid matches: lead must exist and be created on/before the sale\n",
    "phone_join = phone_join[\n",
    "    phone_join[\"lead_id\"].notna() &\n",
    "    phone_join[\"entry_date\"].notna() &\n",
    "    phone_join[\"sale_date\"].notna() &\n",
    "    (phone_join[\"entry_date\"] <= phone_join[\"sale_date\"])\n",
    "]\n",
    "\n",
    "# For each sale, select the lead with entry_date closest to the sale_date (but before it)\n",
    "phone_best = (\n",
    "    phone_join\n",
    "    .assign(time_gap=lambda d: (d[\"sale_date\"] - d[\"entry_date\"]).dt.total_seconds())\n",
    "    .sort_values([\"_sale_row_id\", \"time_gap\"])\n",
    "    .groupby(\"_sale_row_id\", as_index=False)\n",
    "    .first()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: EMAIL-based matching (only for unmatched sales)\n",
    "# -----------------------------\n",
    "matched_sale_ids = set(phone_best[\"_sale_row_id\"])\n",
    "\n",
    "email_candidates = sales_m[~sales_m[\"_sale_row_id\"].isin(matched_sale_ids)]\n",
    "\n",
    "email_join = email_candidates.merge(\n",
    "    leads_m,\n",
    "    how=\"left\",\n",
    "    on=\"email_key\",\n",
    "    suffixes=(\"_sale\", \"_lead\")\n",
    ")\n",
    "\n",
    "email_join = email_join[\n",
    "    email_join[\"lead_id\"].notna() &\n",
    "    email_join[\"entry_date\"].notna() &\n",
    "    email_join[\"sale_date\"].notna() &\n",
    "    (email_join[\"entry_date\"] <= email_join[\"sale_date\"])\n",
    "]\n",
    "\n",
    "email_best = (\n",
    "    email_join\n",
    "    .assign(time_gap=lambda d: (d[\"sale_date\"] - d[\"entry_date\"]).dt.total_seconds())\n",
    "    .sort_values([\"_sale_row_id\", \"time_gap\"])\n",
    "    .groupby(\"_sale_row_id\", as_index=False)\n",
    "    .first()\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Combine PHONE + EMAIL matches\n",
    "# -----------------------------\n",
    "sales_lead_matched = pd.concat([phone_best, email_best], ignore_index=True)\n",
    "\n",
    "# Sanity checks\n",
    "total_sales = len(sales)\n",
    "matched_sales = len(sales_lead_matched)\n",
    "unmatched_sales = total_sales - matched_sales\n",
    "\n",
    "print(\"Sales → Lead matching results:\")\n",
    "print(f\"  Total sales: {total_sales}\")\n",
    "print(f\"  Matched sales: {matched_sales} ({matched_sales / total_sales:.1%})\")\n",
    "print(f\"  Unmatched sales: {unmatched_sales} ({unmatched_sales / total_sales:.1%})\")\n",
    "\n",
    "# Keep only the essential columns for downstream use\n",
    "sales_lead_matched = sales_lead_matched[\n",
    "    [\"_sale_row_id\", \"lead_id\", \"sale_date\", \"phone_agent\", \"user\", \"list_id\"]\n",
    "]\n",
    "\n",
    "# Save for diagnostics / appendix\n",
    "sales_lead_matched.to_csv(\"sales_lead_matched_one_to_one.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f3fb5-ded6-4249-8850-f75101cde44a",
   "metadata": {},
   "source": [
    "## Cell 8 — Build the lead-level modelling table and create sale_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d615c62b-b97d-4372-afaa-5d7723927c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Create one row per lead (unit of analysis).\n",
    "# - Label each lead with sale_flag = 1 if it matched a sale, else 0.\n",
    "\n",
    "# Start from the full Leads table (one row per lead)\n",
    "lead_model = leads.copy()\n",
    "\n",
    "# Identify leads that matched at least one sale (from Cell 7 result)\n",
    "matched_lead_ids = set(sales_lead_matched[\"lead_id\"].dropna().unique())\n",
    "\n",
    "# Create binary outcome variable\n",
    "lead_model[\"sale_flag\"] = lead_model[\"lead_id\"].isin(matched_lead_ids).astype(int)\n",
    "\n",
    "# Attach sale_date to matched leads only (kept sparse by design)\n",
    "lead_model = lead_model.merge(\n",
    "    sales_lead_matched[[\"lead_id\", \"sale_date\"]],\n",
    "    how=\"left\",\n",
    "    on=\"lead_id\"\n",
    ")\n",
    "\n",
    "# Quick checks\n",
    "print(\"Lead-level table shape:\", lead_model.shape)\n",
    "print(\"Conversion rate:\", f\"{lead_model['sale_flag'].mean():.2%}\")\n",
    "print(\"sale_flag counts:\")\n",
    "print(lead_model[\"sale_flag\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645b7fbd-04ad-4dc1-909a-628988e61668",
   "metadata": {},
   "source": [
    "## Cell 9 — EDA for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f937c9-6d57-4cff-9580-913418cd8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Confirm class imbalance\n",
    "# - Sanity-check conversion rates across a few key dimensions\n",
    "# - Ensure features are usable before modelling\n",
    "\n",
    "# Overall class balance (already seen, repeated here for context)\n",
    "print(\"Overall conversion rate:\", f\"{lead_model['sale_flag'].mean():.2%}\")\n",
    "print(\"Class counts:\")\n",
    "print(lead_model[\"sale_flag\"].value_counts())\n",
    "\n",
    "# Conversion rate by campaign (list_id) — top 10 by volume\n",
    "conv_by_list = (\n",
    "    lead_model\n",
    "    .groupby(\"list_id\", dropna=False)\n",
    "    .agg(\n",
    "        leads=(\"lead_id\", \"count\"),\n",
    "        conversion_rate=(\"sale_flag\", \"mean\")\n",
    "    )\n",
    "    .sort_values(\"leads\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 campaigns by lead volume (conversion rates):\")\n",
    "print(conv_by_list)\n",
    "\n",
    "# Conversion rate by lead source — top 10 by volume\n",
    "conv_by_source = (\n",
    "    lead_model\n",
    "    .groupby(\"lead_source\", dropna=False)\n",
    "    .agg(\n",
    "        leads=(\"lead_id\", \"count\"),\n",
    "        conversion_rate=(\"sale_flag\", \"mean\")\n",
    "    )\n",
    "    .sort_values(\"leads\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop 10 lead sources by volume (conversion rates):\")\n",
    "print(conv_by_source)\n",
    "\n",
    "# Conversion rate by agent (user) — only agents with sufficient volume\n",
    "conv_by_agent = (\n",
    "    lead_model\n",
    "    .groupby(\"user\", dropna=False)\n",
    "    .agg(\n",
    "        leads=(\"lead_id\", \"count\"),\n",
    "        conversion_rate=(\"sale_flag\", \"mean\")\n",
    "    )\n",
    "    .query(\"leads >= 200\")   # threshold to avoid noisy rates\n",
    "    .sort_values(\"conversion_rate\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(\"\\nTop agents by conversion rate (min 200 leads):\")\n",
    "print(conv_by_agent)\n",
    "\n",
    "# Missingness check for candidate modelling features\n",
    "candidate_features = [\n",
    "    \"list_id\", \"lead_source\", \"type\", \"state\", \"called_count\",\n",
    "    \"called_since_last_reset\", \"rank\", \"user\"\n",
    "]\n",
    "\n",
    "print(\"\\nMissingness in candidate modelling features:\")\n",
    "print(\n",
    "    lead_model[candidate_features]\n",
    "    .isna()\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .map(lambda x: f\"{x:.2%}\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ecc8c9-c386-4f45-b77e-88fbca3d7d44",
   "metadata": {},
   "source": [
    "## Cell 10 — Feature selection and encoding for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63972b73-991d-402d-8fa6-0b81828d8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Select a small, defensible feature set\n",
    "# - Encode categorical variables for logistic regression\n",
    "# - Prepare X (features) and y (outcome)\n",
    "\n",
    "# Select features to include in the model\n",
    "model_features = [\n",
    "    \"list_id\",\n",
    "    \"lead_source\",\n",
    "    \"type\",\n",
    "    \"state\",\n",
    "    \"called_count\",\n",
    "    \"called_since_last_reset\",\n",
    "    \"rank\",\n",
    "    \"user\"   # agent ID (treated as categorical)\n",
    "]\n",
    "\n",
    "# Subset the modelling table\n",
    "model_df = lead_model[model_features + [\"sale_flag\"]].copy()\n",
    "\n",
    "# Handle missing categorical values by assigning an explicit category\n",
    "for col in [\"list_id\", \"lead_source\", \"type\", \"state\", \"user\"]:\n",
    "    model_df[col] = model_df[col].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Handle missing numeric values (minimal, conservative)\n",
    "model_df[\"called_count\"] = model_df[\"called_count\"].fillna(0)\n",
    "model_df[\"called_since_last_reset\"] = model_df[\"called_since_last_reset\"].fillna(0)\n",
    "model_df[\"rank\"] = model_df[\"rank\"].fillna(0)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(\n",
    "    model_df.drop(columns=[\"sale_flag\"]),\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "# Outcome variable\n",
    "y = model_df[\"sale_flag\"]\n",
    "\n",
    "# Final sanity check\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Outcome distribution:\")\n",
    "print(y.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6ef06-fcd0-4ef8-8868-bf8d202ee4be",
   "metadata": {},
   "source": [
    "## Cell 11 — Logistic regression modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85214f5-d7b3-4a9d-a792-95cfafdc1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Fit a baseline logistic regression model\n",
    "# - Evaluate predictive performance on held-out data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# Train / test split (stratified to preserve class imbalance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Initialise logistic regression\n",
    "# - class_weight='balanced' accounts for severe class imbalance\n",
    "# - max_iter increased to ensure convergence\n",
    "logit = LogisticRegression(\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on test set\n",
    "y_prob = logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate using ROC-AUC (appropriate for imbalanced classification)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"ROC-AUC:\", round(auc, 3))\n",
    "\n",
    "# Threshold-based classification summary at a 0.5 cut-off (reported for interpretability)\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "print(\"\\nClassification report (threshold = 0.5):\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc8f64b-8837-4220-bb56-41c8c637626a",
   "metadata": {},
   "source": [
    "## Cell 12 — Interpretation: key predictors and agent effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff107362-edbd-46a5-a953-4c582d335f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Identify influential predictors from the logistic model\n",
    "# - Summarise agent-level effects to inform allocation decisions\n",
    "\n",
    "# Get model coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": X.columns,\n",
    "    \"coefficient\": logit.coef_[0]\n",
    "})\n",
    "\n",
    "# Rank by absolute effect size\n",
    "coef_df[\"abs_coeff\"] = coef_df[\"coefficient\"].abs()\n",
    "top_coeffs = coef_df.sort_values(\"abs_coeff\", ascending=False).head(15)\n",
    "\n",
    "print(\"Top predictors by absolute coefficient:\")\n",
    "print(top_coeffs[[\"feature\", \"coefficient\"]])\n",
    "\n",
    "# --- Agent effects (interpretable summary) ---\n",
    "# Extract agent-related coefficients (features starting with 'user_')\n",
    "agent_coefs = coef_df[coef_df[\"feature\"].str.startswith(\"user_\")].copy()\n",
    "agent_coefs[\"agent_id\"] = agent_coefs[\"feature\"].str.replace(\"user_\", \"\", regex=False)\n",
    "\n",
    "# Rank agents by coefficient (higher = higher predicted conversion likelihood)\n",
    "top_agents = agent_coefs.sort_values(\"coefficient\", ascending=False).head(10)\n",
    "bottom_agents = agent_coefs.sort_values(\"coefficient\", ascending=True).head(10)\n",
    "\n",
    "print(\"\\nTop agents by model coefficient:\")\n",
    "print(top_agents[[\"agent_id\", \"coefficient\"]])\n",
    "\n",
    "print(\"\\nBottom agents by model coefficient:\")\n",
    "print(bottom_agents[[\"agent_id\", \"coefficient\"]])\n",
    "\n",
    "# --- Allocation implication (simple illustration) ---\n",
    "print(\"\\nAllocation implication:\")\n",
    "print(\n",
    "    \"Predicted conversion probabilities vary systematically by agent, \"\n",
    "    \"suggesting that lead assignment informed by model outputs could \"\n",
    "    \"improve conversion efficiency relative to uniform allocation.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2146394-178d-4a7c-a532-09d491410c11",
   "metadata": {},
   "source": [
    "# Cell 13 — Conditional suitability: Agent × Lead Source interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e7c38c-3f9b-49fb-b6e8-bff335478ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Test whether agent effects vary by lead source (agent–source fit)\n",
    "# - Produce a simple routing table (top agents per lead source)\n",
    "\n",
    "# --- 1) Filter to reduce sparsity and keep results stable ---\n",
    "# Keep only agents with sufficient lead volume\n",
    "agent_counts = lead_model[\"user\"].value_counts(dropna=True)\n",
    "keep_agents = set(agent_counts[agent_counts >= 200].index.astype(str))\n",
    "\n",
    "# Keep only top lead sources by volume\n",
    "top_sources = set(lead_model[\"lead_source\"].value_counts(dropna=True).head(10).index.astype(str))\n",
    "\n",
    "# Build a compact dataframe\n",
    "df_int = lead_model[[\"sale_flag\", \"user\", \"lead_source\"]].copy()\n",
    "df_int[\"user\"] = df_int[\"user\"].fillna(\"Unknown\").astype(str)\n",
    "df_int[\"lead_source\"] = df_int[\"lead_source\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "df_int = df_int[df_int[\"user\"].isin(keep_agents) & df_int[\"lead_source\"].isin(top_sources)].copy()\n",
    "\n",
    "print(\"Interaction dataset shape:\", df_int.shape)\n",
    "print(\"Conversion rate (interaction sample):\", f\"{df_int['sale_flag'].mean():.2%}\")\n",
    "\n",
    "# --- 2) Create main effects + interaction feature ---\n",
    "df_int[\"agent_source\"] = df_int[\"user\"] + \" | \" + df_int[\"lead_source\"]\n",
    "\n",
    "X_int = pd.get_dummies(df_int[[\"user\", \"lead_source\", \"agent_source\"]], drop_first=True)\n",
    "y_int = df_int[\"sale_flag\"]\n",
    "\n",
    "# --- 3) Fit logistic regression with class balancing ---\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_int, y_int, test_size=0.25, random_state=42, stratify=y_int\n",
    ")\n",
    "\n",
    "logit_int = LogisticRegression(class_weight=\"balanced\", max_iter=1000, n_jobs=-1)\n",
    "logit_int.fit(Xtr, ytr)\n",
    "\n",
    "yprob = logit_int.predict_proba(Xte)[:, 1]\n",
    "auc_int = roc_auc_score(yte, yprob)\n",
    "print(\"ROC-AUC (interaction model):\", round(auc_int, 3))\n",
    "\n",
    "# --- 4) Extract top agent–source combinations (interaction terms) ---\n",
    "coef_int = pd.DataFrame({\"feature\": X_int.columns, \"coefficient\": logit_int.coef_[0]})\n",
    "int_terms = coef_int[coef_int[\"feature\"].str.startswith(\"agent_source_\")].copy()\n",
    "int_terms[\"agent_source\"] = int_terms[\"feature\"].str.replace(\"agent_source_\", \"\", regex=False)\n",
    "\n",
    "# Split back into agent and source\n",
    "split = int_terms[\"agent_source\"].str.split(\" \\\\| \", expand=True)\n",
    "int_terms[\"agent_id\"] = split[0]\n",
    "int_terms[\"lead_source\"] = split[1]\n",
    "\n",
    "# For each lead source, show top 5 agents by interaction coefficient\n",
    "top_by_source = (\n",
    "    int_terms.sort_values([\"lead_source\", \"coefficient\"], ascending=[True, False])\n",
    "    .groupby(\"lead_source\", as_index=False)\n",
    "    .head(5)\n",
    "    [[\"lead_source\", \"agent_id\", \"coefficient\"]]\n",
    ")\n",
    "\n",
    "print(\"\\nTop agent–source combinations (top 5 agents per source):\")\n",
    "print(top_by_source)\n",
    "\n",
    "# Save routing-style output for report appendix / recommendation table\n",
    "top_by_source.to_csv(\"routing_top_agents_by_source.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd0fed-84b9-4198-b399-c2d84033cefb",
   "metadata": {},
   "source": [
    "## Cell 14 — Conditional suitability: Agent × State interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cd0e02-7bd8-4b3e-a100-deabc26e0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Examine whether agent performance varies by customer state\n",
    "# - Compare geographic suitability against lead-source effects\n",
    "\n",
    "# --- 1) Filter to ensure stability ---\n",
    "# Keep agents with sufficient volume\n",
    "agent_counts = lead_model[\"user\"].value_counts(dropna=True)\n",
    "keep_agents = set(agent_counts[agent_counts >= 200].index.astype(str))\n",
    "\n",
    "# Keep states with sufficient volume\n",
    "top_states = set(lead_model[\"state\"].value_counts(dropna=True).head(6).index)\n",
    "\n",
    "df_state = lead_model[[\"sale_flag\", \"user\", \"state\"]].copy()\n",
    "df_state[\"user\"] = df_state[\"user\"].fillna(\"Unknown\").astype(str)\n",
    "df_state[\"state\"] = df_state[\"state\"].fillna(\"Unknown\")\n",
    "\n",
    "df_state = df_state[\n",
    "    df_state[\"user\"].isin(keep_agents) & df_state[\"state\"].isin(top_states)\n",
    "].copy()\n",
    "\n",
    "print(\"State interaction dataset shape:\", df_state.shape)\n",
    "print(\"Conversion rate (state interaction sample):\", f\"{df_state['sale_flag'].mean():.2%}\")\n",
    "\n",
    "# --- 2) Create interaction feature ---\n",
    "df_state[\"agent_state\"] = df_state[\"user\"] + \" | \" + df_state[\"state\"]\n",
    "\n",
    "X_state = pd.get_dummies(df_state[[\"user\", \"state\", \"agent_state\"]], drop_first=True)\n",
    "y_state = df_state[\"sale_flag\"]\n",
    "\n",
    "# --- 3) Fit interaction model ---\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_state, y_state, test_size=0.25, random_state=42, stratify=y_state\n",
    ")\n",
    "\n",
    "logit_state = LogisticRegression(class_weight=\"balanced\", max_iter=1000, n_jobs=-1)\n",
    "logit_state.fit(Xtr, ytr)\n",
    "\n",
    "yprob = logit_state.predict_proba(Xte)[:, 1]\n",
    "auc_state = roc_auc_score(yte, yprob)\n",
    "print(\"ROC-AUC (agent × state model):\", round(auc_state, 3))\n",
    "\n",
    "# --- 4) Extract interaction effects ---\n",
    "coef_state = pd.DataFrame({\n",
    "    \"feature\": X_state.columns,\n",
    "    \"coefficient\": logit_state.coef_[0]\n",
    "})\n",
    "\n",
    "int_state = coef_state[coef_state[\"feature\"].str.startswith(\"agent_state_\")].copy()\n",
    "int_state[\"agent_state\"] = int_state[\"feature\"].str.replace(\"agent_state_\", \"\", regex=False)\n",
    "\n",
    "split = int_state[\"agent_state\"].str.split(\" \\\\| \", expand=True)\n",
    "int_state[\"agent_id\"] = split[0]\n",
    "int_state[\"state\"] = split[1]\n",
    "\n",
    "# Top and bottom agents per state\n",
    "top_by_state = (\n",
    "    int_state.sort_values([\"state\", \"coefficient\"], ascending=[True, False])\n",
    "    .groupby(\"state\", as_index=False)\n",
    "    .head(3)[[\"state\", \"agent_id\", \"coefficient\"]]\n",
    ")\n",
    "\n",
    "bottom_by_state = (\n",
    "    int_state.sort_values([\"state\", \"coefficient\"], ascending=[True, True])\n",
    "    .groupby(\"state\", as_index=False)\n",
    "    .head(3)[[\"state\", \"agent_id\", \"coefficient\"]]\n",
    ")\n",
    "\n",
    "print(\"\\nTop agents by state:\")\n",
    "print(top_by_state)\n",
    "\n",
    "print(\"\\nBottom agents by state:\")\n",
    "print(bottom_by_state)\n",
    "\n",
    "# Save for appendix / comparison\n",
    "top_by_state.to_csv(\"routing_top_agents_by_state.csv\", index=False)\n",
    "bottom_by_state.to_csv(\"routing_bottom_agents_by_state.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73119b-7aba-4b24-813a-8eb93c1806d9",
   "metadata": {},
   "source": [
    "## Cell 15 — Results section setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2af8f-f68c-431e-b589-3f846a66b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Define a single, consistent location for all figures and tables produced\n",
    "#   in the results section of this notebook.\n",
    "# - Ensure outputs can be saved and reused without re-running analysis.\n",
    "\n",
    "import os   # Provides file system utilities (directory creation, path handling)\n",
    "\n",
    "# Define output directory for this notebook\n",
    "output_dir = \"outputs_01_core\"     # Centralised folder for model results and visuals\n",
    "\n",
    "# Create the directory if it does not already exist\n",
    "os.makedirs(\n",
    "    output_dir,\n",
    "    exist_ok=True                 # Prevents errors if the folder already exists\n",
    ")\n",
    "\n",
    "# Confirm output location\n",
    "print(\"Results will be saved to:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dcb0f9-b85d-4832-bf4a-40e5d1c837a7",
   "metadata": {},
   "source": [
    "## Cell 16 — Baseline model performance: ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f52c331-08bd-4778-8684-8f59e1c79d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16 — Baseline model performance: ROC curve\n",
    "# Purpose:\n",
    "# - Visualise the baseline model’s ability to discriminate between converted\n",
    "#   and non-converted leads.\n",
    "# - Provide a threshold-independent performance summary that complements\n",
    "#   the ROC-AUC statistic.\n",
    "\n",
    "import matplotlib.pyplot as plt          # Provides plotting functionality for visual outputs\n",
    "from sklearn.metrics import roc_curve    # Generates ROC curve coordinates across thresholds\n",
    "\n",
    "# Compute ROC curve coordinates using predicted probabilities from the held-out test set\n",
    "fpr, tpr, _ = roc_curve(\n",
    "    y_test,                              # True outcomes for the test set\n",
    "    y_prob                               # Predicted conversion probabilities from the baseline model\n",
    ")\n",
    "\n",
    "# Recompute ROC-AUC for consistency with the plotted curve\n",
    "auc_baseline = roc_auc_score(\n",
    "    y_test,\n",
    "    y_prob\n",
    ")\n",
    "\n",
    "# Plot the ROC curve for the baseline model\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    fpr,                                 # False positive rate values\n",
    "    tpr,                                 # True positive rate values\n",
    "    label=f\"Baseline model (AUC = {auc_baseline:.3f})\"\n",
    ")\n",
    "\n",
    "# Add a reference line representing random classification performance\n",
    "plt.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    linestyle=\"--\"\n",
    ")\n",
    "\n",
    "# Add axis labels and title\n",
    "plt.xlabel(\"False Positive Rate\")        # 1 − specificity\n",
    "plt.ylabel(\"True Positive Rate\")         # sensitivity / recall\n",
    "plt.title(\"ROC Curve — Baseline Lead Conversion Model\")\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure for downstream use\n",
    "roc_path = os.path.join(output_dir, \"roc_baseline_model.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(roc_path, dpi=200, bbox_inches=\"tight\")\n",
    "print(\"ROC curve saved to:\", roc_path)\n",
    "\n",
    "# Display the plot in the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5614197-d1d7-4dcd-b85d-c675cfbf2995",
   "metadata": {},
   "source": [
    "## Cell 17 — Model comparison: AUC summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb79c8d7-baa2-46fe-92d0-b08b6fddb74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Summarise predictive performance across all fitted models.\n",
    "# - Enable direct comparison of baseline and interaction specifications.\n",
    "# - Provide a compact, reusable table for downstream visualisation.\n",
    "\n",
    "# Assemble AUC results from previously fitted models\n",
    "auc_summary = pd.DataFrame({\n",
    "    \"model\": [\n",
    "        \"Baseline\",\n",
    "        \"Agent × Lead Source\",\n",
    "        \"Agent × State\"\n",
    "    ],\n",
    "    \"roc_auc\": [\n",
    "        auc_baseline,    # Baseline logistic regression\n",
    "        auc_int,         # Agent × lead source interaction model\n",
    "        auc_state        # Agent × state interaction model\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Sort models by predictive performance (highest AUC first)\n",
    "auc_summary = auc_summary.sort_values(\n",
    "    \"roc_auc\",\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Display the comparison table\n",
    "print(auc_summary)\n",
    "\n",
    "# Save the table for reuse in reporting and appendix material\n",
    "auc_table_path = os.path.join(output_dir, \"auc_model_comparison.csv\")\n",
    "auc_summary.to_csv(auc_table_path, index=False)\n",
    "print(\"AUC summary table saved to:\", auc_table_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a417d-fbc1-4311-a64b-62e10632ad7f",
   "metadata": {},
   "source": [
    "## Cell 18 — Model comparison visual: AUC bar chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e752f-06a9-459a-9400-4e2aedb3970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Visualise predictive performance differences across the fitted models.\n",
    "# - Provide a simple, readable comparison that complements the AUC summary table.\n",
    "\n",
    "# Create a bar chart of ROC-AUC by model\n",
    "plt.figure()\n",
    "plt.bar(\n",
    "    auc_summary[\"model\"],          # Model labels (baseline and interaction specifications)\n",
    "    auc_summary[\"roc_auc\"]         # Corresponding ROC-AUC values\n",
    ")\n",
    "\n",
    "# Add axis labels and title for interpretability\n",
    "plt.ylabel(\"ROC-AUC\")              # y-axis: discrimination performance\n",
    "plt.title(\"ROC-AUC Comparison Across Model Specifications\")\n",
    "plt.xticks(rotation=20, ha=\"right\")  # Improve readability of longer model names\n",
    "\n",
    "# Save the figure for reuse in reporting\n",
    "auc_plot_path = os.path.join(output_dir, \"auc_model_comparison_bar.png\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(auc_plot_path, dpi=200, bbox_inches=\"tight\")\n",
    "print(\"AUC bar chart saved to:\", auc_plot_path)\n",
    "\n",
    "# Display the plot in the notebook\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c44c9e-80dc-422b-8fee-c21197f03834",
   "metadata": {},
   "source": [
    "## Cell 19 — Conversion heterogeneity by lead source (top sources by volume with overall benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b922d5a2-db3d-41ef-8c52-8f2a37fef3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Quantify variation in conversion rates across lead sources.\n",
    "# - Demonstrate that uniform treatment of leads is inefficient.\n",
    "# - Anchor source-level performance against the overall conversion benchmark.\n",
    "\n",
    "# Number of lead sources to display (ranked by lead volume)\n",
    "top_n_sources = 12  # Focus on the main operational drivers while keeping the chart readable\n",
    "\n",
    "# Compute lead volume and conversion rate by lead source\n",
    "source_summary = (\n",
    "    lead_model\n",
    "    .groupby(\"lead_source\", dropna=False)                     # Group leads by originating source\n",
    "    .agg(\n",
    "        leads=(\"lead_id\", \"count\"),                           # Total number of leads per source\n",
    "        conversion_rate=(\"sale_flag\", \"mean\")                 # Mean of sale_flag equals conversion rate\n",
    "    )\n",
    "    .sort_values(\"leads\", ascending=False)                    # Rank by operational importance (volume)\n",
    "    .head(top_n_sources)                                      # Retain only top sources by volume\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Express conversion rates as percentages for interpretability\n",
    "source_summary[\"conversion_rate_pct\"] = source_summary[\"conversion_rate\"] * 100\n",
    "\n",
    "# Calculate overall conversion rate as a benchmark\n",
    "overall_conversion_pct = lead_model[\"sale_flag\"].mean() * 100\n",
    "\n",
    "# Display the summary table\n",
    "print(source_summary)\n",
    "print(f\"\\nOverall conversion rate: {overall_conversion_pct:.2f}%\")\n",
    "\n",
    "# Save the table for reuse\n",
    "source_table_path = os.path.join(\n",
    "    output_dir,\n",
    "    \"conversion_by_lead_source_top_volume.csv\"\n",
    ")\n",
    "source_summary.to_csv(source_table_path, index=False)\n",
    "print(\"Lead source summary table saved to:\", source_table_path)\n",
    "\n",
    "# Plot conversion rate by lead source with overall benchmark\n",
    "plt.figure()\n",
    "plt.bar(\n",
    "    source_summary[\"lead_source\"].astype(str),                # Lead source labels\n",
    "    source_summary[\"conversion_rate_pct\"]                     # Conversion rate (%)\n",
    ")\n",
    "\n",
    "# Add horizontal reference line for overall conversion rate\n",
    "plt.axhline(\n",
    "    y=overall_conversion_pct,                                 # Overall benchmark level\n",
    "    linestyle=\"--\",\n",
    "    label=f\"Overall conversion rate ({overall_conversion_pct:.2f}%)\"\n",
    ")\n",
    "\n",
    "# Add labels and title\n",
    "plt.ylabel(\"Conversion rate (%)\")\n",
    "plt.title(\n",
    "    f\"Conversion Rate by Lead Source (Top {top_n_sources} by lead volume)\"\n",
    ")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure for reuse\n",
    "source_plot_path = os.path.join(\n",
    "    output_dir,\n",
    "    \"conversion_by_lead_source_top_volume_with_benchmark.png\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(source_plot_path, dpi=200, bbox_inches=\"tight\")\n",
    "print(\"Lead source conversion chart saved to:\", source_plot_path)\n",
    "\n",
    "# Display the plot in the notebook\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72820ad5-9bff-4f99-a0a7-fcf6e6a34c59",
   "metadata": {},
   "source": [
    "## Cell 20 — Conversion heterogeneity by agent (minimum lead-volume threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c1145d-6bbb-4aa7-ba5b-befc99c66c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Summarise variation in conversion rates across agents.\n",
    "# - Apply a minimum lead-volume threshold to ensure stable, interpretable comparisons.\n",
    "# - Provide descriptive context before examining conditional agent suitability.\n",
    "\n",
    "# Define minimum number of leads required for an agent to be included\n",
    "min_leads_per_agent = 200  # Aligns with thresholds used in interaction modelling\n",
    "\n",
    "# Compute lead volume and conversion rate by agent\n",
    "agent_summary = (\n",
    "    lead_model\n",
    "    .groupby(\"user\", dropna=False)                           # Group leads by agent ID\n",
    "    .agg(\n",
    "        leads=(\"lead_id\", \"count\"),                          # Total leads handled by the agent\n",
    "        conversion_rate=(\"sale_flag\", \"mean\")                # Mean of sale_flag equals conversion rate\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Retain only agents meeting the minimum lead-volume requirement\n",
    "agent_summary = agent_summary[\n",
    "    agent_summary[\"leads\"] >= min_leads_per_agent\n",
    "].copy()\n",
    "\n",
    "# Express conversion rates as percentages for interpretability\n",
    "agent_summary[\"conversion_rate_pct\"] = agent_summary[\"conversion_rate\"] * 100\n",
    "\n",
    "# Sort agents by conversion rate (highest to lowest)\n",
    "agent_summary = agent_summary.sort_values(\n",
    "    \"conversion_rate\",\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Display a snapshot of agent-level variation\n",
    "print(\"Top 10 agents by conversion rate (min 200 leads):\")\n",
    "print(agent_summary.head(10))\n",
    "\n",
    "print(\"\\nBottom 10 agents by conversion rate (min 200 leads):\")\n",
    "print(agent_summary.tail(10))\n",
    "\n",
    "# Save the full agent-level summary for reference\n",
    "agent_table_path = os.path.join(\n",
    "    output_dir,\n",
    "    \"conversion_by_agent_min_200_leads.csv\"\n",
    ")\n",
    "agent_summary.to_csv(agent_table_path, index=False)\n",
    "print(\"\\nAgent conversion summary table saved to:\", agent_table_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d940e3d1-4398-40e7-8677-e167a9bb7eb4",
   "metadata": {},
   "source": [
    "## Cell 21 — Routing table: top agents by lead source (interaction model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695fbd1f-82d6-4a96-b435-7b6fd7c39afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Translate agent × lead source interaction effects into a practical routing table.\n",
    "# - Identify which agents are most suitable for each major lead source.\n",
    "# - Retain only agents with sufficient exposure to ensure stable recommendations.\n",
    "\n",
    "# Reuse minimum volume threshold applied elsewhere in the notebook\n",
    "min_leads_per_agent = 200\n",
    "\n",
    "# Compute agent lead volumes (cast agent IDs to string for consistency)\n",
    "agent_volumes = (\n",
    "    lead_model\n",
    "    .assign(user=lambda d: d[\"user\"].astype(str))          # Ensure agent ID is string\n",
    "    .groupby(\"user\", dropna=False)\n",
    "    .agg(leads=(\"lead_id\", \"count\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Prepare interaction coefficient table from the fitted interaction model\n",
    "interaction_terms = coef_int.copy()                        # coef_int created in Cell 13\n",
    "interaction_terms = interaction_terms[\n",
    "    interaction_terms[\"feature\"].str.startswith(\"agent_source_\")\n",
    "].copy()\n",
    "\n",
    "# Recover agent ID and lead source from interaction term names\n",
    "interaction_terms[\"agent_source\"] = (\n",
    "    interaction_terms[\"feature\"]\n",
    "    .str.replace(\"agent_source_\", \"\", regex=False)\n",
    ")\n",
    "\n",
    "split = interaction_terms[\"agent_source\"].str.split(\" \\\\| \", expand=True)\n",
    "interaction_terms[\"user\"] = split[0].astype(str)           # Agent ID as string\n",
    "interaction_terms[\"lead_source\"] = split[1]\n",
    "\n",
    "# Attach agent lead volumes\n",
    "interaction_terms = interaction_terms.merge(\n",
    "    agent_volumes,\n",
    "    how=\"left\",\n",
    "    on=\"user\"\n",
    ")\n",
    "\n",
    "# Retain only agents meeting the minimum lead-volume threshold\n",
    "interaction_terms = interaction_terms[\n",
    "    interaction_terms[\"leads\"] >= min_leads_per_agent\n",
    "].copy()\n",
    "\n",
    "# For each lead source, select the top agents by interaction coefficient\n",
    "top_agents_by_source = (\n",
    "    interaction_terms\n",
    "    .sort_values(\n",
    "        [\"lead_source\", \"coefficient\"],\n",
    "        ascending=[True, False]\n",
    "    )\n",
    "    .groupby(\"lead_source\", as_index=False)\n",
    "    .head(3)                                                # Top 3 agents per lead source\n",
    "    [[\"lead_source\", \"user\", \"leads\", \"coefficient\"]]\n",
    ")\n",
    "\n",
    "# Display the routing-style table\n",
    "print(\"Top agents by lead source (interaction model):\")\n",
    "print(top_agents_by_source)\n",
    "\n",
    "# Save routing table for reuse\n",
    "routing_table_path = os.path.join(\n",
    "    output_dir,\n",
    "    \"routing_top_agents_by_lead_source.csv\"\n",
    ")\n",
    "top_agents_by_source.to_csv(routing_table_path, index=False)\n",
    "print(\"\\nRouting table saved to:\", routing_table_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f7cda-76f1-4318-ba78-47375009023c",
   "metadata": {},
   "source": [
    "## Cell 22 — Routing table with lead source context (volume and conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb3b458-ac6c-4dc7-bfd1-6ca5f5374d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purpose:\n",
    "# - Attach lead source volume and baseline conversion rate to the routing table.\n",
    "# - Provide operational context so routing recommendations are not presented in isolation.\n",
    "# - Sort lead sources by lead volume to reflect practical impact.\n",
    "\n",
    "# Compute lead source volume and baseline conversion rate from the full lead-level table\n",
    "source_context = (\n",
    "    lead_model\n",
    "    .groupby(\"lead_source\", dropna=False)\n",
    "    .agg(\n",
    "        source_leads=(\"lead_id\", \"count\"),                 # Total leads generated by the source\n",
    "        source_conversion_rate=(\"sale_flag\", \"mean\")       # Baseline conversion rate for the source\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Express source conversion rate as a percentage for readability\n",
    "source_context[\"source_conversion_rate_pct\"] = source_context[\"source_conversion_rate\"] * 100\n",
    "\n",
    "# Attach source context to the routing table (top agents per source)\n",
    "routing_with_context = top_agents_by_source.merge(\n",
    "    source_context,\n",
    "    how=\"left\",\n",
    "    on=\"lead_source\"\n",
    ")\n",
    "\n",
    "# Sort lead sources by operational importance (highest volume first), then by coefficient\n",
    "routing_with_context = routing_with_context.sort_values(\n",
    "    [\"source_leads\", \"lead_source\", \"coefficient\"],\n",
    "    ascending=[False, True, False]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Display the enriched routing table\n",
    "print(\"Routing table with lead source context:\")\n",
    "print(routing_with_context)\n",
    "\n",
    "# Save enriched routing table for reuse\n",
    "routing_context_path = os.path.join(\n",
    "    output_dir,\n",
    "    \"routing_top_agents_by_lead_source_with_context.csv\"\n",
    ")\n",
    "routing_with_context.to_csv(routing_context_path, index=False)\n",
    "print(\"\\nRouting table with context saved to:\", routing_context_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a8947-63b2-47b2-90c9-53d3566e731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final lead-level modelling table for reuse in descriptive analysis\n",
    "lead_model.to_csv(\"lead_model_final.csv\", index=False)\n",
    "print(\"lead_model saved to lead_model_final.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683afaf4-1d54-4f20-a46d-6a4c4862b58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
